{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch provides modules and classes\n",
    "\n",
    "torch.nn, torch,optim, Dataset, and DataLoader\n",
    "\n",
    "to help create and train neural networks\n",
    "\n",
    "First we will train a basic neural not on mnist without using any features from these models\n",
    "\n",
    "We will later add functionality from each of the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "#create a path object so we can call things like mkdir\n",
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'mnist'\n",
    "\n",
    "# this will create a new directory at the given path\n",
    "PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist\r\n"
     ]
    }
   ],
   "source": [
    "# ok so we know our data folder now contains\n",
    "# a folder called mnist\n",
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get the data\n",
    "\n",
    "URL='http://deeplearning.net/data/mnist/'\n",
    "FILENAME='mnist.pkl.gz'\n",
    "\n",
    "# if the file does not already exist\n",
    "if not (PATH/FILENAME).exists():\n",
    "    # put the content of the download in a variable\n",
    "    content = requests.get(URL+FILENAME).content\n",
    "    # open the path and write the content\n",
    "    (PATH/FILENAME).open('wb').write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.pkl.gz\r\n"
     ]
    }
   ],
   "source": [
    "# great so now mnist contains our dataset\n",
    "# The data set is in numpy array format\n",
    "# It has been stored using pickle, a python-specific format for serializing data\n",
    "# also its been gzipped\n",
    "!ls data/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need these libs to deal with the compression\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "\n",
    "f = gzip.open(PATH/FILENAME)\n",
    "\n",
    "((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these images are being stored as a flattened row of length 784 or 28x28\n",
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff40ebcca90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets see them in 2d\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "img = x_train[7000].reshape(28,28)\n",
    "\n",
    "pyplot.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch uses a torch.tensor rather than numpy arrays\n",
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the elements must first be converted\n",
    "import torch\n",
    "# convert our data to torch tensors\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "n,c = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function Tensor.type>, torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.type, x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a model using nothing but pytorch tensor operations\n",
    "\n",
    "PyTorch provides methods to create random or zero-filled tensors, which we will use to create our weights and bias for a simple linear model. These are just regular tensors, with one very special addition: we tell PyTorch that they require a gradient. This causes PyTorch to record all of the operations done on the tensor, so that it can calculate the gradient during back-propagation automatically!\n",
    "\n",
    "For the weights, we set requires_grad after the initialization, since we don't want that step included in the gradient. (Note that a trailing _ in PyTorch signifies that the operation is performed in-place.)\n",
    "\n",
    "NB: We are initializing the weights here with [Xavier initialisation](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) (by multiplying with 1/sqrt(n))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need sqrt from math\n",
    "from math import sqrt\n",
    "\n",
    "# lets initalize our weights which will be random initally\n",
    "weights = torch.randn(784,10)/math.sqrt(784)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Thanks to PyTorch's ability to calculate gradients automatically, we can use any standard Python function (or callable object) as a model! So let's just write a plain matrix multiplication and broadcasted addition to create a simple linear model. We also need an activation function, so we'll write log_softmax and use it. Remember: although PyTorch provides lots of pre-written loss functions, activation functions, and so forth, you can easily write your own using plain python. PyTorch will even create fast GPU or vectorized CPU code for your function automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): \n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):      \n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the above, the '@' stands for the dot product operation. We will call our function on one batch of data (in this case, 64 images). This is one forward pass. Note that our predictions won't be any better than random at this stage, since we start with random weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.5238, -2.6042, -1.8414, -2.2044, -2.4944, -2.4332, -2.2051, -2.4190,\n",
       "         -2.2444, -2.2884], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64                  # batch size\n",
    "\n",
    "xb = x_train[0:bs]     # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As you see, the preds tensor contains not only the tensor values, but also a gradient function. We'll use this later to do backprop.\n",
    "\n",
    "Let's implement negative log-likelihood to use as the loss function (again, we can just use standard Python):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): \n",
    "    return -input[range(target.long().shape[0]), target.long()].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's check our loss with our random model, so we can see if we improve after a backprop pass later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2800, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs].long()\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's also implement a function to calculate the accuracy of our model. For each prediction, if the index with the largest value matches the target value, then the prediction was correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5   # learning rate\n",
    "epochs = 2 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "#         set_trace()\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0796, grad_fn=<NegBackward>), tensor(1.))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
